{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5amsialYCQLl"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, isnan, when, count, isnull, sum, median, mean, first, max, min, mode\n",
        "from pyspark.sql.types import StructType, StructField, StringType, LongType, DoubleType\n",
        "\n",
        "from pyspark.ml.feature import Bucketizer, QuantileDiscretizer\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import (\n",
        "    StringIndexer,\n",
        "    OneHotEncoder,\n",
        "    VectorAssembler,\n",
        "    StandardScaler\n",
        ")\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OAqd54jTr66c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4df984-f024-46d6-abd1-b87a2f27c442"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0tEahm1UCQLm"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"test\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMH9bFxyCQLn"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wK8SJ1BpCQLp"
      },
      "outputs": [],
      "source": [
        "df=spark.read.csv('drive/MyDrive/Colab Notebooks/cust_data_with_feature_engineering.csv',inferSchema=True,header=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SWS81J-QXPM",
        "outputId": "86a562d0-0c75-42b7-f8d4-a3685115bdc1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+----+-------------------+---------+------------------------------+--------+--------+-------------------+-------+-----+----+--------+-------------+--------------+--------------+----------------+---------------------+-------------------+\n",
            "|_c0|Gender| Age|Has_Mobile_Contract|Area_Code|Currently_Holds_Second_Product|  Tenure|App_User|Acquisition_Channel|Revenue|Label|bins|age_bins|Revenue_Group|Gender_Numeric|Tenure_Numeric|App_User_Numeric|Area_Code_Avg_Revenue|Channel_Avg_Revenue|\n",
            "+---+------+----+-------------------+---------+------------------------------+--------+--------+-------------------+-------+-----+----+--------+-------------+--------------+--------------+----------------+---------------------+-------------------+\n",
            "|  0|Female|48.0|                  1|        1|                             1|1-2 Year|      No|                 12|   2.63|    0| 3.0|   46-55|          Low|             1|             1|               1|   2.7112896825397494|  33.57289910600262|\n",
            "|  1|  Male|58.0|                  1|        3|                             0|1-2 Year|      No|                 12|  21.85|    0| 4.0|     55+|          Low|             0|             1|               1|     24.5248870392396|  33.57289910600262|\n",
            "|  2|  Male|49.0|                  1|        3|                             1|1-2 Year|      No|                 12|   2.63|    0| 3.0|   46-55|          Low|             0|             1|               1|     24.5248870392396|  33.57289910600262|\n",
            "|  3|  Male|40.0|                  1|        6|                             0|1-2 Year|     Yes|                 12|  26.41|    0| 2.0|   36-45|       Medium|             0|             1|               0|     25.1321942675162|  33.57289910600262|\n",
            "|  4|Female|43.0|                  1|        6|                             0|1-2 Year|     Yes|                 12|   2.63|    1| 2.0|   36-45|          Low|             1|             1|               0|     25.1321942675162|  33.57289910600262|\n",
            "|  5|  Male|78.0|                  1|       20|                             1|1-2 Year|      No|                 12|   2.63|    0| 4.0|     55+|          Low|             0|             1|               1|   2.7816485788114558|  33.57289910600262|\n",
            "|  6|  Male|37.0|                  1|       20|                             0|1-2 Year|     Yes|                 12|   2.63|    0| 2.0|   36-45|          Low|             0|             1|               0|   2.7816485788114558|  33.57289910600262|\n",
            "|  7|  Male|59.0|                  1|       20|                             1|1-2 Year|      No|                 12|   2.63|    0| 4.0|     55+|          Low|             0|             1|               1|   2.7816485788114558|  33.57289910600262|\n",
            "|  8|  Male|64.0|                  1|       27|                             1|1-2 Year|      No|                 12|   2.63|    0| 4.0|     55+|          Low|             0|             1|               1|   22.859015232022458|  33.57289910600262|\n",
            "|  9|  Male|65.0|                  1|       28|                             1|1-2 Year|      No|                 12|  32.31|    0| 4.0|     55+|         High|             0|             1|               1|    38.66919513982096|  33.57289910600262|\n",
            "| 10|  Male|43.0|                  1|       28|                             0|1-2 Year|     Yes|                 12|  69.86|    0| 2.0|   36-45|    Very High|             0|             1|               0|    38.66919513982096|  33.57289910600262|\n",
            "| 11|Female|57.0|                  1|       28|                             0|1-2 Year|     Yes|                 12|   2.63|    0| 4.0|     55+|          Low|             1|             1|               0|    38.66919513982096|  33.57289910600262|\n",
            "| 12|  Male|55.0|                  1|       28|                             1|1-2 Year|      No|                 12|  38.89|    0| 4.0|     55+|         High|             0|             1|               1|    38.66919513982096|  33.57289910600262|\n",
            "| 13|Female|35.0|                  1|       28|                             0|1-2 Year|     Yes|                 12|  40.09|    0| 2.0|   36-45|    Very High|             1|             1|               0|    38.66919513982096|  33.57289910600262|\n",
            "| 14|  Male|44.0|                  1|       28|                             0|1-2 Year|      No|                 12|  32.17|    0| 2.0|   36-45|         High|             0|             1|               1|    38.66919513982096|  33.57289910600262|\n",
            "| 15|  Male|40.0|                  1|       28|                             1|1-2 Year|      No|                 12|  43.39|    0| 2.0|   36-45|    Very High|             0|             1|               1|    38.66919513982096|  33.57289910600262|\n",
            "| 16|  Male|43.0|                  1|       28|                             0|1-2 Year|     Yes|                 12|  93.34|    1| 2.0|   36-45|    Very High|             0|             1|               0|    38.66919513982096|  33.57289910600262|\n",
            "| 17|  Male|62.0|                  1|       28|                             1|1-2 Year|      No|                 12|   2.63|    0| 4.0|     55+|          Low|             0|             1|               1|    38.66919513982096|  33.57289910600262|\n",
            "| 18|  Male|42.0|                  1|       28|                             1|1-2 Year|      No|                 12|   2.63|    0| 2.0|   36-45|          Low|             0|             1|               1|    38.66919513982096|  33.57289910600262|\n",
            "| 19|Female|51.0|                  1|       28|                             0|1-2 Year|     Yes|                 12|  28.41|    0| 3.0|   46-55|       Medium|             1|             1|               0|    38.66919513982096|  33.57289910600262|\n",
            "+---+------+----+-------------------+---------+------------------------------+--------+--------+-------------------+-------+-----+----+--------+-------------+--------------+--------------+----------------+---------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train - Test split"
      ],
      "metadata": {
        "id": "fEwgAS5vSjER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "lxHxWtsSc3Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features\n",
        "categorical_features = ['Area_Code', 'Tenure', 'Acquisition_Channel']\n",
        "numerical_features = ['Age', 'Revenue']\n",
        "\n",
        "# Create preprocessing stages for categorical features\n",
        "string_indexers = [\n",
        "    StringIndexer(\n",
        "        inputCol=col,\n",
        "        outputCol=f\"{col}_indexed\",\n",
        "        handleInvalid=\"keep\"\n",
        "    ) for col in categorical_features\n",
        "]\n",
        "\n",
        "encoders = [\n",
        "    OneHotEncoder(\n",
        "        inputCol=f\"{col}_indexed\",\n",
        "        outputCol=f\"{col}_encoded\"\n",
        "    ) for col in categorical_features\n",
        "]\n",
        "\n",
        "# Create preprocessing stages for numerical features\n",
        "numerical_assembler = VectorAssembler(\n",
        "    inputCols=numerical_features,\n",
        "    outputCol=\"numerical_features\"\n",
        ")\n",
        "\n",
        "numerical_scaler = StandardScaler(\n",
        "    inputCol=\"numerical_features\",\n",
        "    outputCol=\"scaled_numerical_features\",\n",
        "    withStd=True,\n",
        "    withMean=True\n",
        ")\n",
        "\n",
        "# Get the encoded categorical feature column names\n",
        "encoded_categorical_features = [f\"{col}_encoded\" for col in categorical_features]\n",
        "\n",
        "# Combine all features (categorical and numerical) into a single vector\n",
        "feature_assembler = VectorAssembler(\n",
        "    inputCols=encoded_categorical_features + [\"scaled_numerical_features\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "# Create the random forest classifier\n",
        "rf = RandomForestClassifier(\n",
        "    labelCol=\"label\",\n",
        "    featuresCol=\"features\",\n",
        "    numTrees=100,\n",
        ")\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline(stages=[\n",
        "    *string_indexers,    # Unpack all string indexers\n",
        "    *encoders,           # Unpack all encoders\n",
        "    numerical_assembler,\n",
        "    numerical_scaler,\n",
        "    feature_assembler,\n",
        "    rf\n",
        "])\n",
        "\n",
        "# Fit the pipeline on training data\n",
        "model = pipeline.fit(train_df)\n",
        "\n",
        "# Make predictions on test data\n",
        "predictions = model.transform(test_df)"
      ],
      "metadata": {
        "id": "vx0VOo-ISlFn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}